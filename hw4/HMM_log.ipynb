{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW4: Hidden Markov Model (Loaded or Fair Die?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.linalg as sla\n",
    "from logdouble import logdouble\n",
    "\n",
    "tol = 1e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.) Pre-process the `rolls.txt` file into a vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "sides = 6\n",
    "num_rolls = 3000\n",
    "rolls = np.zeros(num_rolls, dtype=int)\n",
    "counter = 0\n",
    "with open(\"rolls.txt\") as file:\n",
    "    for line in file:\n",
    "        roll = int(line)\n",
    "        rolls[counter] = roll\n",
    "        counter += 1\n",
    "rolls = np.array(rolls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.) Initialize our transition, emission, and initial probabilities: `A` will be the transition matrix (with shape $2,2$), `B` will be the emission matrix (with shape $2, 6$), and `pi` will be our initial probability vector of length $2$. From here on, die `0` refers to the fair die, while die `1` refers to the loaded die. I'm using this terminology and [this Wikipedia article](https://en.wikipedia.org/wiki/Baum%E2%80%93Welch_algorithm), as I think the steps explained there are a bit clearer than the notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.ndarray((2, 2), dtype=float)\n",
    "#Let's call the 1-index the loaded die, and the 0-index the fair die\n",
    "A[0][0] = 0.9\n",
    "A[0][1] = 0.1\n",
    "A[1][0] = 0.2\n",
    "A[1][1] = 0.8\n",
    "\n",
    "#Given we're using dice i, whats the probability we roll j?\n",
    "B = np.ndarray((2, 6), dtype=float)\n",
    "B[0] = 1/sides\n",
    "B[1] = 1/sides\n",
    "\n",
    "#Guess for initial die\n",
    "pi = np.array([0.5, 0.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.) Define our parameter updates function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UPDATE PARAMETERS FUNCTION\n",
    "def update_parameters(gamma, xi, T):\n",
    "    \"\"\"\n",
    "    returns pi*, A*, B*\n",
    "    \"\"\"\n",
    "    pi_star = np.array([gamma[0][0], gamma[0][1]])\n",
    "    numerator_matrix = np.zeros((2, 2))\n",
    "    denominator_matrix = np.zeros((2, 2))\n",
    "    for t in range(T - 1):\n",
    "        for i in range(2):\n",
    "            denominator_matrix[i][0] += gamma[t][i]\n",
    "            denominator_matrix[i][1] = denominator_matrix[i][0]\n",
    "            for j in range(2):\n",
    "                numerator_matrix[i][j] += xi[t][i][j]\n",
    "    A_star = np.zeros((2, 2))\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            A_star[i][j] = numerator_matrix[i][j]/denominator_matrix[i][j]\n",
    "    \n",
    "    \n",
    "    numerator_matrix = np.zeros((2, 6))\n",
    "    denominator_matrix = np.zeros((2, 6))\n",
    "    for t in range(T):\n",
    "        for i in range(2):\n",
    "            for j in range(6):\n",
    "                denominator_matrix[i][j] += gamma[t][i]\n",
    "\n",
    "            for j in range(6):\n",
    "                if rolls[t] - j == 0:\n",
    "                    numerator_matrix[i][j] += gamma[t][i]\n",
    "\n",
    "    B_star = np.zeros((2, 6))\n",
    "    for i in range(2):\n",
    "        for j in range(6):\n",
    "            B_star[i][j] = numerator_matrix[i][j]/denominator_matrix[i][j]\n",
    "\n",
    "    return pi_star, A_star, B_star"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.) Initialize `alpha`, `beta`, `gamma`, and `xi`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 300\n",
    "alpha = np.zeros((T, 2))\n",
    "beta = np.zeros((T, 2))\n",
    "gamma = np.zeros((T, 2))\n",
    "xi = np.zeros((T, 2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.) Execute Baum-Welch Algorithm. Going to scale `alpha` and `beta` to ensure we avoid underflow. I found [these slides](https://courses.engr.illinois.edu/ece417/fa2021/lectures/lec16.pdf) that show how we can mitigate this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_hat = beta_hat = np.zeros((T, 2))\n",
    "alpha_tilde = beta_tilde = np.zeros((T, 2))\n",
    "#g is our scaling constant vector\n",
    "g = np.zeros(T)\n",
    "g[0] = 1 \n",
    "while True:\n",
    "    #ALPHAs:\n",
    "    #initialize alphas\n",
    "    \n",
    "    alpha[0][0] = pi[0]*B[0][rolls[0]]\n",
    "    alpha[0][1] = pi[1]*B[1][rolls[0]]\n",
    "    #recursively compute for each timestep\n",
    "    for t in range(0, T - 1):\n",
    "        for i in range(2):\n",
    "            alpha[t + 1][i] = B[i][rolls[t + 1]]\n",
    "            sum = 0.0\n",
    "            for j in range(2):\n",
    "                sum += alpha[t][j]*A[j][i]\n",
    "            alpha[t + 1][i] *= sum\n",
    "    break\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    #ALPHAs:\n",
    "    #initialize alphas\n",
    "    alpha[0][0] = pi[0]*B[0][rolls[0]]\n",
    "    alpha[0][1] = pi[1]*B[1][rolls[0]]\n",
    "    #recursively compute for each timestep\n",
    "    for t in range(0, T - 1):\n",
    "        for i in range(2):\n",
    "            alpha[t + 1][i] = B[i][rolls[t + 1]]\n",
    "            sum = 0.0\n",
    "            for j in range(2):\n",
    "                sum += alpha[t][j]*A[j][i]\n",
    "            alpha[t + 1][i] *= sum\n",
    "\n",
    "    #BETAS:\n",
    "    #initialize betas\n",
    "    beta[T - 1][0] = beta[T - 1][1] = 1\n",
    "    for t in reversed(range(T - 1)):\n",
    "        for i in range(2):\n",
    "            for j in range(2):\n",
    "                beta[t][i] += beta[t + 1][j]*A[i][j]*B[j][rolls[t + 1]]\n",
    "    \n",
    "    #GAMMAS:\n",
    "    for t in range(T):\n",
    "        # i = 0\n",
    "        numerator_0 = alpha[t][0]*beta[t][0]\n",
    "        numerator_1 = alpha[t][1]*beta[t][1]\n",
    "        denominator = numerator_0 + numerator_1\n",
    "        if denominator == 0:\n",
    "            gamma[t][0] = gamma[t][1] = 0\n",
    "            continue\n",
    "        gamma[t][0] = numerator_0/denominator\n",
    "        gamma[t][1] = 1 - gamma[t][0]\n",
    "\n",
    "\n",
    "    #XIS\n",
    "    for t in range(T- 1):\n",
    "        #only need to calculate denominator once per time-step\n",
    "        denom = 0.0\n",
    "        for k in range(2):\n",
    "            for w in range(2):\n",
    "                term = alpha[t][k]*A[k][w]*beta[t + 1][w]*B[w][rolls[t + 1]]\n",
    "                denom += term\n",
    "\n",
    "        for i in range(2):\n",
    "            for j in range(2):\n",
    "                num = alpha[t][i]*A[i][j]*beta[t+1][j]*B[j][rolls[t + 1]]\n",
    "                xi[t][i][j] = num/denom\n",
    "\n",
    "    #Now update parameters            \n",
    "    pi_star, A_star, B_star = update_parameters(gamma, xi, T)\n",
    "    pi_norm = sla.norm(pi_star - pi)\n",
    "    A_norm = sla.norm(A_star - A)\n",
    "    B_norm = sla.norm(B_star - B)\n",
    "\n",
    "    #Terminate once updates are within tolerance of last iteration\n",
    "    if pi_norm < tol and A_norm < tol and B_norm < tol:\n",
    "        break\n",
    "    else:\n",
    "        pi = pi_star\n",
    "        A = A_star\n",
    "        B = B_star                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.) Now, we can view our final transmission, emission, and initial probabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transition Matrix:\n",
      "[[0.83348245 0.16649693]\n",
      " [0.29550444 0.70453135]]\n",
      "\n",
      "\n",
      "Emission Matrix:\n",
      "[[9.08239827e-06 2.01843272e-01 1.97877371e-01 1.36712376e-01\n",
      "  1.36690939e-01 3.26866960e-01]\n",
      " [3.46686944e-01 6.90654216e-02 4.85834270e-02 1.91329798e-01\n",
      "  1.91367038e-01 1.52967371e-01]]\n",
      "\n",
      "\n",
      "Initial probabilities:\n",
      "[9.40989105e-24 1.00000000e+00]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "A_final = A\n",
    "B_final = B\n",
    "pi_final = pi\n",
    "\n",
    "print(f\"Transition Matrix:\\n{A_final}\\n\\n\")\n",
    "print(f\"Emission Matrix:\\n{B_final}\\n\\n\")\n",
    "print(f\"Initial probabilities:\\n{pi_final}\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pycourse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
