{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW5: LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process the Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training_firsts (and seconds) will be a lists of length 6036 each. Each element of these lists is a sentence vector, where each element corresponds to the words in the sentence. both `<s>` and `</s>` are included in each sentence vector. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING\n",
    "training_size = 6036\n",
    "training_firsts = []\n",
    "training_secs = []\n",
    "with open(\"bobsue-data/bobsue.seq2seq.train.tsv\") as trainfile:\n",
    "    for line in trainfile:\n",
    "        separated = line.split()\n",
    "        for i in range(len(separated)):\n",
    "            if separated[i] == \"</s>\":\n",
    "                sent1 = separated[:i + 1]\n",
    "                sent2 = separated[i + 1:]\n",
    "                break\n",
    "        training_firsts.append(sent1)\n",
    "        training_secs.append(sent2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we repeat for validation and testing sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VALIDATION\n",
    "validation_size = 750\n",
    "valid_firsts = []\n",
    "valid_secs = []\n",
    "with open(\"bobsue-data/bobsue.seq2seq.dev.tsv\") as valfile:\n",
    "    for line in valfile:\n",
    "        separated = line.split()\n",
    "        for i in range(len(separated)):\n",
    "            if separated[i] == \"</s>\":\n",
    "                sent1 = separated[:i + 1]\n",
    "                sent2 = separated[i + 1:]\n",
    "                break\n",
    "        valid_firsts.append(sent1)\n",
    "        valid_secs.append(sent2)\n",
    "\n",
    "# TESTING\n",
    "testing_size = 750\n",
    "test_firsts = []\n",
    "test_secs = []\n",
    "with open(\"bobsue-data/bobsue.seq2seq.test.tsv\") as testfile:\n",
    "    for line in testfile:\n",
    "        separated = line.split()\n",
    "        for i in range(len(separated)):\n",
    "            if separated[i] == \"</s>\":\n",
    "                sent1 = separated[:i + 1]\n",
    "                sent2 = separated[i + 1:]\n",
    "                break\n",
    "        test_firsts.append(sent1)\n",
    "        test_secs.append(sent2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import vocabulary and assign each vocab to a 200-d embedding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre-process Vocabulary\n",
    "voc = []\n",
    "with open('bobsue-data/bobsue.voc.txt') as vocfile:\n",
    "    for line in vocfile:\n",
    "        line = line.split()\n",
    "        voc.append(line[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOVE\n",
    "word2idx = {}\n",
    "idx = 0\n",
    "vectors = []\n",
    "with open('embedding-data/glove.6B.200d.txt') as embedfile:\n",
    "    for embedline in embedfile:\n",
    "        embedvec_str = embedline.split()\n",
    "        embedword = embedvec_str[0]\n",
    "        embedvec = np.array(embedvec_str[1:]).astype(np.double)\n",
    "        word2idx[embedword] = idx\n",
    "        idx += 1\n",
    "        vectors.append(embedvec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's use GloVe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for vocword in voc:\n",
    "    if vocword not in word2idx:\n",
    "        #If a word from our vocab is not in GloVe, then we add an entry w/ random values\n",
    "        #there are only 85 words in our vocab not in GloVe out of ~1500\n",
    "        word2idx[vocword] = idx\n",
    "        idx += 1\n",
    "        rand_vec = np.random.rand(10) * 2 - 1\n",
    "        vectors.append(rand_vec)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pycourse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
